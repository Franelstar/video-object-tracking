{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "# from pyimagesearch.centroidtracker import CentroidTracker\n",
    "# from pyimagesearch.trackableobject import TrackableObject\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=50, maxDistance=50):\n",
    "        # initialize the next unique object ID along with two ordered\n",
    "        # dictionaries used to keep track of mapping a given object\n",
    "        # ID to its centroid and number of consecutive frames it has\n",
    "        # been marked as \"disappeared\", respectively\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "\n",
    "        # store the number of maximum consecutive frames a given\n",
    "        # object is allowed to be marked as \"disappeared\" until we\n",
    "        # need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "        # store the maximum distance between centroids to associate\n",
    "        # an object -- if the distance is larger than this maximum\n",
    "        # distance we'll start to mark the object as \"disappeared\"\n",
    "        self.maxDistance = maxDistance\n",
    "\n",
    "    def register(self, centroid):\n",
    "        # when registering an object we use the next available object\n",
    "        # ID to store the centroid\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        # check to see if the list of input bounding box rectangles\n",
    "        # is empty\n",
    "        if len(rects) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            return self.objects\n",
    "\n",
    "        # initialize an array of input centroids for the current frame\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "        # loop over the bounding box rectangles\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "\n",
    "        # otherwise, are are currently tracking objects so we need to\n",
    "        # try to match the input centroids to existing object\n",
    "        # centroids\n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            # compute the distance between each pair of object\n",
    "            # centroids and input centroids, respectively -- our\n",
    "            # goal will be to match an input centroid to an existing\n",
    "            # object centroid\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            # in order to perform this matching we must (1) find the\n",
    "            # smallest value in each row and then (2) sort the row\n",
    "            # indexes based on their minimum values so that the row\n",
    "            # with the smallest value as at the *front* of the index\n",
    "            # list\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "            # next, we perform a similar process on the columns by\n",
    "            # finding the smallest value in each column and then\n",
    "            # sorting using the previously computed row index list\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            # in order to determine if we need to update, register,\n",
    "            # or deregister an object we need to keep track of which\n",
    "            # of the rows and column indexes we have already examined\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # loop over the combination of the (row, column) index\n",
    "            # tuples\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                # if we have already examined either the row or\n",
    "                # column value before, ignore it\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                # if the distance between centroids is greater than\n",
    "                # the maximum distance, do not associate the two\n",
    "                # centroids to the same object\n",
    "                if D[row, col] > self.maxDistance:\n",
    "                    continue\n",
    "\n",
    "                # otherwise, grab the object ID for the current row,\n",
    "                # set its new centroid, and reset the disappeared\n",
    "                # counter\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # indicate that we have examined each of the row and\n",
    "                # column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # compute both the row and column index we have NOT yet\n",
    "            # examined\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            # in the event that the number of object centroids is\n",
    "            # equal or greater than the number of input centroids\n",
    "            # we need to check and see if some of these objects have\n",
    "            # potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "                    # check to see if the number of consecutive\n",
    "                    # frames the object has been marked \"disappeared\"\n",
    "                    # for warrants deregistering the object\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "            # otherwise, if the number of input centroids is greater\n",
    "            # than the number of existing object centroids we need to\n",
    "            # register each new input centroid as a trackable object\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "\n",
    "        # return the set of trackable objects\n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackableObject:\n",
    "    def __init__(self, objectID, centroid):\n",
    "        # store the object ID, then initialize a list of centroids\n",
    "        # using the current centroid\n",
    "        self.objectID = objectID\n",
    "        self.centroids = [centroid]\n",
    "\n",
    "        # initialize a boolean used to indicate if the object has\n",
    "        # already been counted or not\n",
    "        self.counted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--prototxt\", required=True,\n",
    "                help=\"path to Caffe 'deploy' prototxt file\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "                help=\"path to Caffe pre-trained model\")\n",
    "ap.add_argument(\"-i\", \"--input\", type=str,\n",
    "                help=\"path to optional input video file\")\n",
    "ap.add_argument(\"-o\", \"--output\", type=str,\n",
    "                help=\"path to optional output video file\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.4,\n",
    "                help=\"minimum probability to filter weak detections\")\n",
    "ap.add_argument(\"-s\", \"--skip-frames\", type=int, default=30,\n",
    "                help=\"# of skip frames between detections\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxt_arg = 'MobileNetSSD_deploy.prototxt'\n",
    "model_arg = 'MobileNetSSD_deploy.caffemodel'\n",
    "video_arg = \"\"\n",
    "label_arg = 'person'\n",
    "output_arg = ''\n",
    "confidence_arg = 0.2\n",
    "skip_frames_arg = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "# net = cv.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
    "net = cv.dnn.readNetFromCaffe(prototxt_arg, model_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "# if a video path was not supplied, grab a reference to the webcam\n",
    "# if not args.get(\"input\", False):\n",
    "if not video_arg:\n",
    "    print(\"[INFO] starting video stream...\")\n",
    "    vs = VideoStream(src=0).start()\n",
    "    time.sleep(2.0)\n",
    "# otherwise, grab a reference to the video file\n",
    "else:\n",
    "    print(\"[INFO] opening video file...\")\n",
    "    # vs = cv.VideoCapture(video_arg)\n",
    "    vs = cv.VideoCapture(video_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the video writer (we'll instantiate later if need be)\n",
    "writer = None\n",
    "\n",
    "# initialize the frame dimensions (we'll set them as soon as we read\n",
    "# the first frame from the video)\n",
    "W = None\n",
    "H = None\n",
    "\n",
    "# instantiate our centroid tracker, then initialize a list to store\n",
    "# each of our dlib correlation trackers, followed by a dictionary to\n",
    "# map each unique object ID to a TrackableObject\n",
    "ct = CentroidTracker(maxDisappeared=40, maxDistance=50)\n",
    "trackers = []\n",
    "trackableObjects = {}\n",
    "\n",
    "# initialize the total number of frames processed thus far, along\n",
    "# with the total number of objects that have moved either up or down\n",
    "totalFrames = 0\n",
    "totalDown = 0\n",
    "totalUp = 0\n",
    "\n",
    "# start the frames per second throughput estimator\n",
    "fps = FPS().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] elapsed time: 22.21\n",
      "[INFO] approx. FPS: 33.78\n"
     ]
    }
   ],
   "source": [
    "# loop over frames from the video stream\n",
    "while True:\n",
    "    # grab the next frame and handle if we are reading from either\n",
    "    # VideoCapture or VideoStream\n",
    "    frame = vs.read()\n",
    "    # frame = frame[1] if args.get(\"input\", False) else frame\n",
    "    frame = frame[1] if video_arg else frame\n",
    "\n",
    "    # if we are viewing a video and we did not grab a frame then we\n",
    "    # have reached the end of the video\n",
    "    # if args[\"input\"] is not None and frame is None:\n",
    "    if video_arg is not None and frame is None:\n",
    "        break\n",
    "        \n",
    "    # resize the frame to have a maximum width of 500 pixels (the\n",
    "    # less data we have, the faster we can process it), then convert\n",
    "    # the frame from BGR to RGB for dlib\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    # if the frame dimensions are empty, set them\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "        \n",
    "    # if we are supposed to be writing a video to disk, initialize\n",
    "    # the writer\n",
    "    # if args[\"output\"] is not None and writer is None:\n",
    "    if output_arg is not None and writer is None:\n",
    "        fourcc = cv.VideoWriter_fourcc(*\"MJPG\")\n",
    "        # writer = cv.VideoWriter(args[\"output\"], fourcc, 30, (W, H), True)\n",
    "        writer = cv.VideoWriter(output_arg, fourcc, 30, (W, H), True)\n",
    "        \n",
    "    # initialize the current status along with our list of bounding\n",
    "    # box rectangles returned by either (1) our object detector or\n",
    "    # (2) the correlation trackers\n",
    "    status = \"Waiting\"\n",
    "    rects = []\n",
    "    # check to see if we should run a more computationally expensive\n",
    "    # object detection method to aid our tracker\n",
    "    # if totalFrames % args[\"skip_frames\"] == 0:\n",
    "    if totalFrames % skip_frames_arg == 0:\n",
    "        # set the status and initialize our new set of object trackers\n",
    "        status = \"Detecting\"\n",
    "        trackers = []\n",
    "        \n",
    "        # convert the frame to a blob and pass the blob through the\n",
    "        # network and obtain the detections\n",
    "        blob = cv.dnn.blobFromImage(frame, 0.007843, (W, H), 127.5)\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # loop over the detections\n",
    "        for i in np.arange(0, detections.shape[2]):\n",
    "            # extract the confidence (i.e., probability) associated\n",
    "            # with the prediction\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            # filter out weak detections by requiring a minimum\n",
    "            # confidence\n",
    "            # if confidence > args[\"confidence\"]:\n",
    "            if confidence > confidence_arg:\n",
    "                # extract the index of the class label from the\n",
    "                # detections list\n",
    "                idx = int(detections[0, 0, i, 1])\n",
    "                \n",
    "                # if the class label is not a person, ignore it\n",
    "                if CLASSES[idx] != \"person\":\n",
    "                    continue\n",
    "                    \n",
    "                # compute the (x, y)-coordinates of the bounding box\n",
    "                # for the object\n",
    "                box = detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                \n",
    "                # construct a dlib rectangle object from the bounding\n",
    "                # box coordinates and then start the dlib correlation tracker\n",
    "                tracker = dlib.correlation_tracker()\n",
    "                rect = dlib.rectangle(startX, startY, endX, endY)\n",
    "                tracker.start_track(rgb, rect)\n",
    "                \n",
    "                # add the tracker to our list of trackers so we can\n",
    "                # utilize it during skip frames\n",
    "                trackers.append(tracker)\n",
    "                \n",
    "    # otherwise, we should utilize our object *trackers* rather than\n",
    "    # object *detectors* to obtain a higher frame processing throughput\n",
    "    else:\n",
    "        # loop over the trackers\n",
    "        for tracker in trackers:\n",
    "            # set the status of our system to be 'tracking' rather\n",
    "            # than 'waiting' or 'detecting'\n",
    "            status = \"Tracking\"\n",
    "            \n",
    "            # update the tracker and grab the updated position\n",
    "            tracker.update(rgb)\n",
    "            pos = tracker.get_position()\n",
    "            \n",
    "            # unpack the position object\n",
    "            startX = int(pos.left())\n",
    "            startY = int(pos.top())\n",
    "            endX = int(pos.right())\n",
    "            endY = int(pos.bottom())\n",
    "            \n",
    "            # add the bounding box coordinates to the rectangles list\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            \n",
    "    # draw a horizontal line in the center of the frame -- once an\n",
    "    # object crosses this line we will determine whether they were\n",
    "    # moving 'up' or 'down'\n",
    "    cv.line(frame, (0, H // 2), (W, H // 2), (0, 255, 255), 2)\n",
    "    \n",
    "    # use the centroid tracker to associate the (1) old object\n",
    "    # centroids with (2) the newly computed object centroids\n",
    "    objects = ct.update(rects)\n",
    "    \n",
    "    # loop over the tracked objects\n",
    "    for (objectID, centroid) in objects.items():\n",
    "        # check to see if a trackable object exists for the current\n",
    "        # object ID\n",
    "        to = trackableObjects.get(objectID, None)\n",
    "        \n",
    "        # if there is no existing trackable object, create one\n",
    "        if to is None:\n",
    "            to = TrackableObject(objectID, centroid)\n",
    "            \n",
    "        # otherwise, there is a trackable object so we can utilize it\n",
    "        # to determine direction\n",
    "        else:\n",
    "            # the difference between the y-coordinate of the *current*\n",
    "            # centroid and the mean of *previous* centroids will tell\n",
    "            # us in which direction the object is moving (negative for\n",
    "            # 'up' and positive for 'down')\n",
    "            y = [c[1] for c in to.centroids]\n",
    "            direction = centroid[1] - np.mean(y)\n",
    "            to.centroids.append(centroid)\n",
    "            \n",
    "            # check to see if the object has been counted or not\n",
    "            if not to.counted:\n",
    "                # if the direction is negative (indicating the object\n",
    "                # is moving up) AND the centroid is above the center\n",
    "                # line, count the object\n",
    "                if direction < 0 and centroid[1] < H // 2:\n",
    "                    totalUp += 1\n",
    "                    to.counted = True\n",
    "                    \n",
    "                # if the direction is positive (indicating the object\n",
    "                # is moving down) AND the centroid is below the\n",
    "                # center line, count the object\n",
    "                elif direction > 0 and centroid[1] > H // 2:\n",
    "                    totalDown += 1\n",
    "                    to.counted = True\n",
    "        # store the trackable object in our dictionary\n",
    "        trackableObjects[objectID] = to\n",
    "        \n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "        text = \"ID {}\".format(objectID)\n",
    "        cv.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "    \n",
    "    # construct a tuple of information we will be displaying on the\n",
    "    # frame\n",
    "    info = [\n",
    "        (\"Up\", totalUp),\n",
    "        (\"Down\", totalDown),\n",
    "        (\"Status\", status),\n",
    "    ]\n",
    "\n",
    "    # loop over the info tuples and draw them on our frame\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        text = \"{}: {}\".format(k, v)\n",
    "        cv.putText(frame, text, (10, H - ((i * 20) + 20)),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "    # check to see if we should write the frame to disk\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "        \n",
    "    # show the output frame\n",
    "    cv.imshow(\"Frame\", frame)\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    \n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "    # increment the total number of frames processed thus far and\n",
    "    # then update the FPS counter\n",
    "    totalFrames += 1\n",
    "    fps.update()\n",
    "    \n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# check to see if we need to release the video writer pointer\n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "\n",
    "# if we are not using a video file, stop the camera video stream\n",
    "# if not args.get(\"input\", False):\n",
    "if not video_arg:\n",
    "    vs.stop()\n",
    "\n",
    "# otherwise, release the video file pointer\n",
    "else:\n",
    "    vs.release()\n",
    "\n",
    "# close any open windows\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
